[2023-11-03 10:55]

Plan: 
- Explore data: plot some images, understand format, get basic dataset statistics

- Train U-Net from scratch
    - output channels: 1 + thresholding, or 2 + softmax
    - MSE
    - eval MSE, maybe structural metrics
- Cookiecutter template: start with notebooks, maybe turn into py modules later

Doing:
- Download dataset
- Exploratory Data Analysis notebook - read data, preprocess, plot samples

[2023-11-05 23:55]
Tiling done
- crop, pad, mask
- untiling needs testing (skipping for now)

[2023-11-07 14:02]
Training works

Plan:
- Eval notebook - visualize predictions
- ONNX runner

- dataset handling
    - fixed dataset splits filelists, contain only filenames
    - all preprocessing done live
    - directory structure assumed:
        <dataset_root>
            - filelists
                - train/val/test.csv
            - scenes
                - <file1..N>
            - masks
                - <file1..N>


- Model output and postprocessing
    - output logits, BCEWithLogitsLoss, manual sigmoid() after, or use .predict()
    - 2 channels + softmax within the model

[2023-11-08 00:37]
Next:
- Train on full dataset  #DONE#
- Log to W&B  #DONE#
- Train padded
- Use padding and mask
- 7mins+ for datasets loading  #DONE#
- Augmentations?

metacentrum packages missing:
torchinfo
wandb  # praha
segmentation_models_pytorch

Next:
- mirror back changes from metacentrum  #DONE#
- Own eval metrics impl  #DONE#
- Wandb table sample predictions  #DONE#
- Dice loss  #DONE#

Ideas:
- Loss combinations can be wrapped in a single criterion object  #DONE#
- Label smoothing 0.05 - 0.95 
    - no positive change for BCEWithLogitsLoss
    - Dice - shouldn't matter at all

What's wrong:
- Model implementation - try existing #DONE#
- Loss - tried multiple
- Learning Rate - tried many
- Data - @@@
- Batch size - tried 1


